{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('o365Data.csv', dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = df['EmailSubject'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt_subjects = [s.lower() for s in all_subjects if isinstance(s,str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mailbox\n",
    "# mbox = mailbox.mbox('emails.mbox')\n",
    "# non_receipt_subjects = []\n",
    "# for message in mbox:\n",
    "#     payload = message.get_payload(decode=False)\n",
    "#     non_receipt_subjects.append(message['Subject'])\n",
    "# #     if isinstance(payload,list):\n",
    "# #         non_receipt_emails.append(payload[0])\n",
    "# #     else:\n",
    "# #         non_receipt_emails.append(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmail_df = pd.read_csv('gmail_training_data.csv', dtype=object)\n",
    "gmail_df['Subjects'].replace('', np.nan, inplace=True)\n",
    "gmail_df.dropna(subset=['Subjects'], inplace=True)\n",
    "\n",
    "x_train = gmail_df['Subjects'].tolist()\n",
    "y_train = gmail_df['Is_Receipt'].tolist()\n",
    "y_train = np.array(y_train).astype(np.float).tolist()\n",
    "\n",
    "x_train = x_train + receipt_subjects\n",
    "y_train = y_train + np.ones(len(receipt_subjects)).astype(np.float).tolist()\n",
    "\n",
    "test_df = pd.read_csv('test_data.csv', dtype=object)\n",
    "test_df['Subjects'].replace('', np.nan, inplace=True)\n",
    "test_df.dropna(subset=['Subjects'], inplace=True)\n",
    "\n",
    "x_test = test_df['Subjects'].str.lower().tolist()\n",
    "y_test = test_df['Is_Receipt'].tolist()\n",
    "y_test = np.array(y_test).astype(np.float).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the test set\n",
    "\n",
    "# import csv\n",
    "\n",
    "# subs = [s for s in non_receipt_subjects if isinstance(s,str)]\n",
    "# receipt_words = ['invoice','receipt','amazon','paypal','payment','confirmation','trip','booking','order','reservation','confirmed','itinerary','statement','folio','bill']\n",
    "\n",
    "# receipt_subs = [s.lower() for s in subs if any(word.lower() in s.lower() for word in receipt_words)]\n",
    "# non_receipt_subs = [s.lower() for s in subs if not any(word.lower() in s.lower() for word in receipt_words)]\n",
    "\n",
    "# all_subs = receipt_subs + non_receipt_subs\n",
    "    \n",
    "# with open(\"test_set.csv\",'w') as resultFile:\n",
    "#     wr = csv.writer(resultFile, dialect='excel')\n",
    "#     for row in receipt_subs:\n",
    "#         wr.writerows([[row,1]])\n",
    "#     for row in non_receipt_subs:\n",
    "#         wr.writerows([[row,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gmail_subjects(subs): \n",
    "    subs = [s for s in subs if isinstance(s,str)]\n",
    "    \n",
    "#    remove_words = ['invoice','utf','utf-8','receipt','amazon','paypal','payment','confirmation','hughes','trip','booking','lance','weston','order','reservation','confirmed','itinerary','statement','folio','bill']\n",
    "    remove_words = ['utf','utf-8']\n",
    "\n",
    "    return[s.lower() for s in subs if not any(word.lower() in s.lower() for word in remove_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_receipt_subjects = clean_gmail_subjects(non_receipt_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # takes in two lists. the negative list and positive and returns a randomized list off all \n",
    "# # data along with 1 or 0 labels \n",
    "# def get_randomized_data_with_labels(zeros_list,ones_list):\n",
    "#     labels = np.zeros(len(zeros_list)).tolist() + np.ones(len(ones_list)).tolist()\n",
    "    \n",
    "#     all_data = zeros_list + ones_list\n",
    "#     combined = list(zip(all_data, labels))\n",
    "#     random.shuffle(combined)\n",
    "\n",
    "#     all_data[:], labels[:] = zip(*combined)\n",
    "#     return all_data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects, labels = get_randomized_data_with_labels(non_receipt_subjects,receipt_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predicted = []\n",
    "\n",
    "def classify(x_train,y_train,x_test,y_test):\n",
    "    global predicted\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=42)\n",
    "    vectorizer = CountVectorizer()\n",
    "#     clf = MultinomialNB()\n",
    "    clf = SGDClassifier(loss='hinge', penalty='l1', alpha=1e-4, random_state=42, max_iter=7, tol=None)\n",
    "    pipe = Pipeline([('vect', vectorizer),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', clf)\n",
    "                        ])\n",
    "                        \n",
    "    pipe.fit(x_train, y_train)  \n",
    "    predicted = pipe.predict(x_test)\n",
    "    \n",
    "    return np.mean(predicted == y_test), clf, vectorizer,pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, clf, vectorizer,pipe = classify(x_train,y_train,x_test,y_test)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = [x_test[i] for i in range(len(x_test)) if y_test[i] == 0 and predicted[i] == 1]\n",
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 20,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# body = \"your card was declined\"\n",
    "\n",
    "# pipe.predict([body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_receipt(subject):\n",
    "    return pipe.predict([subject])[0] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features_names(n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = [x[1] for x in coefs_with_fns[:-(n + 1):-1]]\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print (\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_most_informative_features(vectorizer,clf,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}